\documentclass[11pt,twoside,a4paper]{report}

\usepackage{listings}
\title{PyTorch Notes}

\author{Amir Nourinia}

\begin{document}
\maketitle
\tableofcontents
\section{Preface}
The Notes are based on deeplizard video seris on PyTorch.
\chapter{Introduction}

PyTorch is a thin layer library. Tensor library is really close to ndim numpy arrays. It is really easy to move calculation to gpu with PyTorch.
PyTorch is based on Torch wich is written in Lua language. Soumith is the person behind PyTorch library. one of the advantages of PyTorch is that is debugable.
PyTorch is created and maintained in Facebook, since Soumith is working there.

\section{PyTorch Packages}
PyTorch contains few packages namely:

\begin{itemize}
    \item torch: The top-level PyTorch package and tensor library
    \item torch.nn: A subpackage that contains modules and extensible classes for building neural networks.
    \item torch.autograd: A subpackage that supports all the differentiable Tensor operations in PyTorch.
    \item torch.nn.functional: A functional interface that contains typical operations used for building neural networks, like loss functions, activation functions and
    convolution operations.
    \item torch.optim: A subpackage that contains standard optimization operations like SGD and Adam.
    \item torch.utils: A subpackage that contains utility classes like data sets and data loaders that make data preprocessing easier.
    \item torchvision: A package that provides access to popular datasets, model architectures, and image trasnformations for computer vision.
\end{itemize}

\section{Philosophy of PyTorch}

\begin{itemize}
    \item Stay out of the way
    \item Cater to the impatient
    \item Promote linear code-flow
    \item Full interop with the Python ecosystem
    \item Be as fast as anything else
\end{itemize}

Because of these philosophy we can use our own favorite debugger. In tensorflow for example we can not debug the python, since it runs in a C++ enviornment on the back.
Because of this PyTorch is the to go framework for research. This is also because, PyTorch uses a dynamic computational graph. This means that the graph is generated on the fly as the operations are created. This is in contrast to static graphs that are fully determined before the actual operations occur.
It just so happens that many of the cutting edge research topics in deep learning are requiring or benefiting greatly from dynamic graphs. 

A very good read on DL: http://colah.github.io/

\section{Getting PyTorch}
Go to pytoch main website and choose the appropriate package you need to download.
But at the time of the writing of this document, the command is: 

python3 -m pip install --user -U torch torchvision

I prefer to install it the local directory in my home folder for ease of package managementa and avoiding conflicts with system python packages. 

\section{Future}
The future of software development is machines writing software. Machines are fast and they are inexhaustible. As long as there is data, architecture and creativity the machines can write the sofware.

\section{CUDA}
GPUs bring parrallel programming into the picture. DNN are embarrassingly Prallel algorithms this means the GPU which has thousands of cores can be massivly beneficial.

If a computation can be done in parallel we can excel at it using GPUs.

With PyTorch the CUDA comes ready to use. All we need is to have CUDA supporting GPU.

Much of PyTorch is written in python but it drops to lower level languages C and C++ at the bottlenecks.


t = torch.tensor([1,2,3])
t \# prints t
tCuda = t.cuda() \# t moves to gpu
t \# prints t and shows the device='cuda'



GPU is faster only for particular tasks. Moving data from CPU to GPU is costly, so this does not give us any performance boost for small calculations.
GPU is good for parrallel taks. So for serial tasks this does not make sense.

Deep Learning along with many other scientific computing task are leading into a new programming model called GPGPU Computing which stands for General Purpose
GPU Computing. There is a paper with this name by Bogdan Oancea, Tudorel Andrei, Raluca Mariana Dragoescu.

Nvidia has envisioned this era 10 years ago, that is why they created CUDA 10 years ago, eventhough it is only recently taking off. 


Apps, Frameworks
PyTorch

---

Libraries such as CUDA, cuDNN

---

GPU

\chapter{Tensors}
We use tensor for any dimension of the data. So tensor is generalization of the data.

\section{Rank}
Number of dimensions present within the tenosr. How many indicies do we need. Differnt from mathematical rank definition.

\begin{lstlisting}
dd = [
    [1,2,3],
    [4,5,6],
    [7,8,9]
]
t = torch.tensor(dd)
t
type(t)

t.shape # will result in torch.Size([3,3])

rank = len (x.shape)

t.reshape(1,9)
\end{lstlisting}

\end{document}